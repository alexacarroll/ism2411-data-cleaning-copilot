GitHub Copilot helped me build the foundation of my data cleaning script, particularly for functions like load_data, handle_missing_values, and remove_invalid_rows. I started by writing detailed comments describing each functionâ€™s purpose, and Copilot suggested usable code that followed pandas conventions. However, I refined nearly every suggestion to make it more accurate and consistent with the dataset. For example, I modified the missing-value function to drop only rows missing price or qty, corrected a column typo (df.columns), and ensured all column names were lowercase to avoid errors.

Through this process, I learned how important data consistency and naming conventions are when cleaning datasets in Python. I also developed stronger debugging skills by resolving KeyErrors and testing my code step by step. This project showed me how AI tools can accelerate development but still require human oversight, logical reasoning, and testing. I now feel more confident in building structured, reproducible data-cleaning pipelines using pandas and GitHub.
